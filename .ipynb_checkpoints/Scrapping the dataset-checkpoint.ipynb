{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b72b19",
   "metadata": {},
   "source": [
    "# Scrapping the data from www.timeanddate.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf65b930",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6039f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.parse as urlparse\n",
    "from urllib.request import urlopen, Request\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0c5ae3",
   "metadata": {},
   "source": [
    "## Get URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52883dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.timeanddate.com/weather/belgium/antwerp/historic?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd3822",
   "metadata": {},
   "source": [
    "## Scarpped data with tags for every year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ab1392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scarp_year(year):\n",
    "    \n",
    "    all_df = pd.DataFrame()\n",
    "    months = range(1,13)\n",
    "    \n",
    "    for month in months:\n",
    "            url = f\"{base_url}month={month}&year={year}\"\n",
    "            page = urlopen(url)\n",
    "            soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "            Data = []\n",
    "            table = soup.find('table', attrs={'id':'wt-his'})\n",
    "            for tr in table.find('tbody').find_all('tr'):\n",
    "                dict = {}\n",
    "                dict['time'] = tr.find('th').text.strip()\n",
    "                all_td = tr.find_all('td')\n",
    "                dict['temp'] = all_td[1].text\n",
    "                dict['weather'] = all_td[2].text\n",
    "                dict['wind'] = all_td[3].text\n",
    "                arrow = all_td[4].text\n",
    "                dict['humidity'] = all_td[5].text\n",
    "                dict['barometer'] = all_td[6].text\n",
    "                dict['visibility'] = all_td[7].text\n",
    "                Data.append(dict)\n",
    "\n",
    "            date_select = soup.find('select', attrs={'id': 'wt-his-select'})\n",
    "            for option in date_select.find_all('option'):\n",
    "                day = option.text.split()[0]\n",
    "                date_str = f\"{day} {month} {year}\"\n",
    "                date = datetime.strptime(date_str, \"%d %m %Y\").strftime(\"%Y-%m-%d\")\n",
    "                day_url = f\"{base_url}day={option['value']}&month={month}&year={year}\"\n",
    "                day_page = urlopen(day_url)\n",
    "                day_soup = BeautifulSoup(day_page, \"html.parser\")\n",
    "                day_table = day_soup.find('table', attrs={'id':'wt-his'})\n",
    "                for tr in day_table.find('tbody').find_all('tr'):\n",
    "                    dict = {}\n",
    "                    dict['date'] = str(date)\n",
    "                    dict['time'] = tr.find('th').text.strip()\n",
    "                    all_td = tr.find_all('td')\n",
    "                    dict['temp'] = all_td[1].text\n",
    "                    dict['weather'] = all_td[2].text\n",
    "                    dict['wind'] = all_td[3].text\n",
    "                    arrow = all_td[4].text\n",
    "                    dict['humidity'] = all_td[5].text\n",
    "                    dict['barometer'] = all_td[6].text\n",
    "                    dict['visibility'] = all_td[7].text\n",
    "                    Data.append(dict)\n",
    "            df_month = pd.DataFrame(Data)\n",
    "            all_df = pd.concat([all_df, df_month]).reset_index(drop=True)\n",
    "            \n",
    "    \n",
    "    return all_df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa2603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wranlge(year):\n",
    "    df = scarp_year(year)\n",
    "    df['time'] = df['time'].str[:5]\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba3cbc",
   "metadata": {},
   "source": [
    "## Scrapping the years from 2012 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6958fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2012 = wranlge(2012)  # done\n",
    "df_2012.to_csv('datasets/year_2012.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a162a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013 = wranlge(2013)  # done\n",
    "df_2013.to_csv('datasets/year_2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5d63bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = wranlge(2014)  # done\n",
    "df_2014.to_csv('datasets/year_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0230109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = wranlge(2015)  # done\n",
    "df_2015.to_csv('datasets/year_2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7418539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = wranlge(2016)  # done\n",
    "df_2016.to_csv('datasets/year_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de308ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = wranlge(2017)  # done\n",
    "df_2017.to_csv('datasets/year_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b662483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = wranlge(2018)  # done\n",
    "df_2018.to_csv('datasets/year_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eedd99c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = wranlge(2019) # done\n",
    "df_2019.to_csv('datasets/year_2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe177fde",
   "metadata": {},
   "source": [
    "## Concat all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc53dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12 = pd.read_csv('datasets/year_2012.csv')\n",
    "df_13 = pd.read_csv('datasets/year_2013.csv')\n",
    "df_14 = pd.read_csv('datasets/year_2014.csv')\n",
    "df_15 = pd.read_csv('datasets/year_2015.csv')\n",
    "df_16 = pd.read_csv('datasets/year_2016.csv')\n",
    "df_17 = pd.read_csv('datasets/year_2017.csv')\n",
    "df_18 = pd.read_csv('datasets/year_2018.csv')\n",
    "df_19 = pd.read_csv('datasets/year_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48abb659",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([df_12, df_13, df_14, df_15, df_16, df_17, df_18, df_19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67b33a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv('datasets/weather_in_Antwerp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da1eb0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
